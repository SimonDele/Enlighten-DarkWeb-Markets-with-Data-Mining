# Accurency
acc <- round((sum(diag(conf)) / sum(conf)*100),2)
print(conf)
cat("\n")
cat("       ")
compTab <- TableCaption(compTab, "Sellers Prediction / Decision Tree method")
Result <- c(acc,compTab)
return(Result)
}
#accDTseller
ResultDT1 <- Dtsellers()
compTab <- ResultDT1[2]
compCap <- figureCaption(compCap, "Seller prediction / Decision Tree")
sprintf("The accuracy is : %.2f %%", ResultDT1[1])
#----------------------------------------------------------------------
#                  Decision tree - CART algorithm
#   Prediction of the seller knowing the price / category / origin
#                              Results
#-----------------------------------------------------------------------
Dtsellers2 <- function(){
#-----------------
#   New Data
#-----------------
# Select all "Drugs & Chemicals" ads
matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
dectree.data <- data[matching_vector,]
# Select the column of the data that are interesting for the tree
# ie removing colunm like "id" or "url" that don't give any informations
dectree.data <- subset(dectree.data, select=c(origin,category,seller,priceUnitDose))
# Subset : choose the colunm that you want
# Handling : column categorie
# Regular expression for spliting the categories
regex <- "/(.*)/(.*)/(.*)"
cat <- str_match(dectree.data$category, regex)
dectree.data$category <- cat[,3] # keep only the second part
# Handling : seller
tab_sel <- table(dectree.data$seller)
tab_sel <- sort(tab_sel, decreasing=TRUE)  # Sorting (biggest in first)
tab_sel <- tab_sel[1:10] # Taking only the most important : main sellers
name_sel <- names(tab_sel)
# New data keeping only the main sellers
dectree.data <-subset(dectree.data, seller %in% name_sel)
# Random rows :
dectree.data <- dectree.data[sample(nrow(dectree.data),nrow(dectree.data),replace=FALSE), ]
#---------------------
#   Decision tree
#---------------------
# Factor
dectree.data$seller <- factor(dectree.data$seller)
# Half of the data for making the decision tree
train.data <- dectree.data[1:(floor(nrow(dectree.data))/2),]
# Creation of the tree
tree <- rpart(seller ~.,data=train.data, method="class")
#--------------------
#   Prediction
#--------------------
# The other half for the prediction
pred.data <- dectree.data[(floor(nrow(dectree.data)/2)+1):nrow(dectree.data),]
# Making prediction
pred <- predict(tree,pred.data,type="class")
# Analysis:
# Comparison between the result and the prediction (prediction in colunm)
conf <- table(pred.data[,match("seller",names(pred.data))],pred)
# Accurency
acc <- round((sum(diag(conf)) / sum(conf)*100),2)
return(acc)
}
acc1 <- Dtsellers2()
sprintf("The accuracy is : %.2f %%", acc1)
#----------------------------------------------------------------------------------
#                       Bayesian Classification - Naive
#   Prediction of the Seller knowing the origin / price / category
#-----------------------------------------------------------------------------------
BayesSellersV1 <- function(){
#-----------------
#   New Data
#-----------------
# Select all "Drugs & Chemicals" ads
matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
bayesian.data <- data[matching_vector,]
# Select the column of the data that are interesting
# ie removing colunm like "id" or "url" that don't give any informations
bayesian.data <- subset(bayesian.data, select=c(origin,category,seller,priceUnitDose))
# Subset : choose the colunm that you want
# Handling : column category
# Regular expression for spliting the categories
regex <- "/(.*)/(.*)/(.*)"
cat <- str_match(bayesian.data$category, regex)
bayesian.data$category <- cat[,3] # keep only the second part
sellers <- names(sort(table(bayesian.data$seller), decreasing = TRUE))[1:10]
bayesian.data <-subset(bayesian.data, seller %in% sellers)
bayesian.data$seller <- factor(bayesian.data$seller, labels = sellers)
#---------------------
#   Bayesian stat
#---------------------
# Random rows :
bayesian.data <- bayesian.data[sample(nrow(bayesian.data),nrow(bayesian.data),replace=FALSE), ]
train.data <- bayesian.data[1:floor(nrow(bayesian.data)/2),]
pred.data <- bayesian.data[(floor(nrow(bayesian.data)/2)+1):nrow(bayesian.data),]
model <- naiveBayes(seller ~ ., data =  train.data)
preds <- predict(model, newdata = pred.data)
conf_matrix <- table(preds, pred.data$seller)
acc <- round(sum(diag(conf_matrix)) / sum(conf_matrix)*100, 2)
return(acc)
}
accBayesV1 <- BayesSellersV1()
sprintf("The accuracy is : %.2f %%", accBayesV1)
#----------------------------------------------------------------------------------
#                       Bayesian Classification - Naive
#   Prediction of the Seller knowing the origin / price / category / products_sold / date creation
#-----------------------------------------------------------------------------------
BayesSellers <- function(){
#-----------------
#   New Data
#-----------------
# Select all "Drugs & Chemicals" ads
matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
bayesian.data <- data[matching_vector,]
# Select the column of the data that are interesting
# ie removing colunm like "id" or "url" that don't give any informations
bayesian.data <- subset(bayesian.data, select=c(origin,category,seller,priceUnitDose, sold_since, products_sold))
# Subset : choose the colunm that you want
# Handling : column category
# Regular expression for spliting the categories
regex <- "/(.*)/(.*)/(.*)"
cat <- str_match(bayesian.data$category, regex)
bayesian.data$category <- cat[,3] # keep only the second part
sellers <- names(sort(table(bayesian.data$seller), decreasing = TRUE))[1:10]
bayesian.data <-subset(bayesian.data, seller %in% sellers)
bayesian.data$seller <- factor(bayesian.data$seller, labels = sellers)
#---------------------
#   Bayesian stat
#---------------------
# Random rows :
bayesian.data <- bayesian.data[sample(nrow(bayesian.data),nrow(bayesian.data),replace=FALSE), ]
train.data <- bayesian.data[1:floor(nrow(bayesian.data)/2),]
pred.data <- bayesian.data[(floor(nrow(bayesian.data)/2)+1):nrow(bayesian.data),]
model <- naiveBayes(seller ~ ., data =  train.data)
preds <- predict(model, newdata = pred.data)
conf_matrix <- table(preds, pred.data$seller)
acc <- round(sum(diag(conf_matrix)) / sum(conf_matrix)*100, 2)
# Display
conf_matrix <- data.frame(conf_matrix)
names(conf_matrix) <- c("Sellers","Prediction","Freq")
print(conf_matrix)
return(acc)
}
accBayesV2 <- BayesSellers()
compTab <- TableCaption(compTab, "Sellers Prediction / Naive Bayesian Classification")
sprintf("The accuracy is : %.2f %%", accBayesV2)
TM_nb_sellers <- 50
#----------------------------------------------------------------------
#             Algo to predict sellers given words from their text
#-----------------------------------------------------------------------
#https://journal.r-project.org/archive/2013/RJ-2013-001/RJ-2013-001.pdf
TMPredictSeller <- function(TM_nb_sellers){
# Select all "Drugs & Chemicals" ads
matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
new.data <- data[matching_vector,]
# Random rows :
new.data <- new.data[sample(nrow(new.data),nrow(new.data),replace=FALSE), ]
# Handling : seller
tab_sel <- table(new.data$seller)
tab_sel <- sort(tab_sel, decreasing=TRUE)  # Sorting (biggest in first)
tab_sel <- tab_sel[1:TM_nb_sellers] # Taking only the most important : main sellers
name_sel <- names(tab_sel)
# New data keeping only the main sellers
new.data <-subset(new.data, seller %in% name_sel)
new.data$seller <- factor(new.data$seller)
# CREATE THE DOCUMENT-TERM MATRIX
doc_matrix <- create_matrix(new.data$ad, language="english", removeNumbers=TRUE,
stemWords=TRUE, removeSparseTerms=.998)
container <- create_container(doc_matrix, new.data$seller, trainSize=1:round(0.75*nrow(new.data)),
testSize=round(0.75*nrow(new.data)+1,0):nrow(new.data), virgin=FALSE)
SVM <- train_model(container,"SVM")
SVM_CLASSIFY <- classify_model(container, SVM)
test <- new.data[round(0.75*nrow(new.data)+1,0):nrow(new.data),]
# Comparison between the result and the prediction (prediction in colunm)
conf <- table(test[,match("seller",names(test))],SVM_CLASSIFY$SVM_LABEL)
# Accuracy :
acc <- round((sum(diag(conf)) / sum(conf)*100),2)
# Display
conf <- data.frame(conf)
names(conf) <- c("Sellers","Prediction","Freq")
#print(conf)
return (acc)
}
accTM <- TMPredictSeller(TM_nb_sellers)
sprintf("The accuracy is : %.2f %%", accTM)
#--------------------------------------------------------
#       Association Rules - Apriori algorithm
#     Guess if this dealer is selling this drugs
#--------------------------------------------------------
AssRSellersCat <- function(){
#------------------------------
#  New Data frame for analysis
#------------------------------
# Select all ads of "Drugs & Chemicals"
matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
data_drugs <- data[matching_vector, ]
# Handling of this categories
# Regular expression for spliting the categories
regex <- "/(.*)/(.*)/(.*)"
cat_exp <- str_match(data_drugs$category, regex)
data_drugs$category <- cat_exp[,3]
# Get rid of category "Other"
matching_vector <- !c( str_detect(data_drugs$category, "Other"))
data_drugs <- data_drugs[matching_vector, ]
# List all the sellers
sellers <-sort(table(data_drugs$seller), decreasing = TRUE)
sellers <- sellers[ sellers != "Null"]
sellers <- sellers [1:100]
#List all categories concerning drugs
list_category <- table(data_drugs[,"category"])
list_cat_drugs <- list_category [ list_category != 0]
# Step 1 : initialise a data.frame with the information of the first seller
# Select all categories of the seller
matching_vector <- c( str_detect(data$seller, names(sellers)[1]))
cat_seller <-summary(data.frame(data[matching_vector, "category"]))
# Loop which creates a boolean vector which tells if the seller sells stuffs in each category
bool_cat <-c()
bool_vec <-c()
for( i in 1: length(list_cat_drugs)){
bool_vec <- str_detect(cat_seller, names(list_cat_drugs)[i])
bool <- FALSE
for(j in 1:length(bool_vec)){
bool <- bool || bool_vec[j]
}
bool_cat[i] <- bool
}
cat_seller.data <- t(data.frame(bool_cat))
colnames(cat_seller.data) <- names(list_cat_drugs)
#Step 2 : Do the same for the other sellers
for(k in 2 : length(sellers)){
# Select all categories of the seller
matching_vector <- c( str_detect(data$seller, names(sellers)[k]))
cat_seller <-summary(data.frame(data[matching_vector, "category"]))
# Loop which creates a boolean vector which tells if the seller sells stuffs in each category
bool_cat <-c()
bool_vec <-c()
for( i in 1: length(list_cat_drugs)){
bool_vec <- str_detect(cat_seller, names(list_cat_drugs)[i])
bool <- FALSE
for(j in 1:length(bool_vec)){
bool <- bool || bool_vec[j]
}
bool_cat[i] <- bool
}
cat_seller.data <- rbind(cat_seller.data,bool_cat)
}
rownames(cat_seller.data)<- names(sellers)
#-------------------------
#      Ass Rules
#-------------------------
# Association Rules with rhs containing "Ecstasy" only
rules <- apriori(cat_seller.data,
parameter = list(minlen=2, supp=0.05, conf=0.8),
appearance = list(rhs=c("Ecstasy"),default="lhs"),
control = list(verbose=F))
rules.sorted <- sort(rules, by="lift")
rules.sorted@quality$support <- round(rules.sorted@quality$support, 3)
rules.sorted@quality$confidence <- round(rules.sorted@quality$confidence, 2)
rules.sorted@quality$lift <- round(rules.sorted@quality$lift, 2)
arules::inspect(rules.sorted[1:10], linebreak = TRUE)
cat("\n")
cat("             ")
compTab <- TableCaption(compTab, "Cluster of drugs / Association Rules")
# Plot graph of rules
plot(rules.sorted[1:5], method="graph", control=list(type="items"),main ="")
mtext("Association Rules on the product range of sellers" , cex = 1.2)
# Frame
box(which = "outer", lty = "solid")
return(compTab)
}
compTab <- AssRSellersCat()
compCap <- figureCaption(compCap, "Cluster of drugs / Association Rules")
#----------------------------------------------------------------------
#                  Decision tree - CART algorithm
#   Prediction of the country knowing the  price / category
#-----------------------------------------------------------------------
DTorigin <- function(){
#-----------------
#   New Data
#-----------------
# Select all "Drugs & Chemicals" ads
matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
dectree.data <- data[matching_vector,]
# Select the column of the data that are interesting for the tree
# ie removing colunm like "id" or "url" that don't give any informations
dectree.data <- subset(dectree.data, select=c(origin,category,priceUnitDose))
# Subset : choose the colunm that you want
# Handling : column categorie
# Regular expression for spliting the categories
regex <- "/(.*)/(.*)/(.*)"
cat <- str_match(dectree.data$category, regex)
dectree.data$category <- cat[,3] # keep only the second part
# Handling : country
dectree.data <- dectree.data[which(dectree.data$origin != "Worldwide"),]
tab_coun <- table(dectree.data$origin)
tab_coun <- sort(tab_coun, decreasing=TRUE)  # Sorting (biggest in first)
tab_coun <- tab_coun[1:5] # Taking only the most important : main sellers
name_coun <- names(tab_coun)
# New data keeping only the main dealers
dectree.data <-subset(dectree.data, origin %in% name_coun)
# Random rows :
dectree.data <- dectree.data[sample(nrow(dectree.data),nrow(dectree.data),replace=FALSE), ]
#---------------------
#   Decision tree
#---------------------
# Factor
dectree.data$origin <- factor(dectree.data$origin)
# Half of the data for making the decision tree
train <- dectree.data[1:(floor(nrow(dectree.data))/2),]
# Creation of the tree
tree <- rpart(origin ~.,data=train, method="class")
# Plot
fancyRpartPlot(tree, sub="")
# Frame
box(which = "outer", lty = "solid")
#--------------------
#   Prediction
#--------------------
# The other half for the prediction
test <- dectree.data[(floor(nrow(dectree.data)/2)+1):nrow(dectree.data),]
# Making prediction
pred <- predict(tree,test,type="class")
# Analysis:
# Comparison between the result and the prediction (prediction in colunm)
conf <- table(test[,match("origin",names(test))],pred)
# Accuracy :
acc <- round((sum(diag(conf)) / sum(conf)*100),2)
print(conf)
cat("\n")
cat("           ")
compTab <- TableCaption(compTab, "Origins Prediction / Decision Tree method")
Result <- c(acc,compTab)
return(Result)
}
ResultDT2 <- DTorigin()
compTab <- ResultDT2[2]
compCap <- figureCaption(compCap, "Origins prediction / Decision Tree")
#--------------------------------------------------------
#       Association Rules - Apriori algorithm
#     Guess if United States is the origin of the ad
#--------------------------------------------------------
AssROriginSellerCat <- function(){
#------------------------------
#  New Data frame for analysis
#------------------------------
# Select all ads of "Drugs & Chemicals"
matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
data_drugs <- data[matching_vector, ]
# Select some columns
asso.data <- subset(data_drugs, select = c(origin,category))
# Get rid of the first part of the category name "/Drugs & Chemicals/"
asso.data$category <- gsub(pattern = "/Drugs & Chemicals/", replacement = "", asso.data$category)
asso.data$origin <- factor(asso.data$origin)
asso.data$category <-factor(asso.data$category)
# asso.data$seller <- factor(asso.data$seller)
# Association Rules with rhs containing one given country only
rules <- apriori(asso.data,
parameter = list(minlen=2, supp=0.0005, conf=0.5),
appearance = list(rhs=c("origin=United States"),default="lhs"),
control = list(verbose=F))
rules.sorted <- sort(rules, by="lift")
rules.sorted@quality$support <- round(rules.sorted@quality$support, 3)
rules.sorted@quality$confidence <- round(rules.sorted@quality$confidence, 2)
rules.sorted@quality$lift <- round(rules.sorted@quality$lift, 2)
arules::inspect(rules.sorted)
cat("\n")
cat("               ")
compTab <- TableCaption(compTab, "Origin Prediction / Association Rules")
# Plot graph of rules
plot(rules.sorted, method="graph", control=list(type="items"),main ="")
mtext("Association Rules on the category and seller to deduce the country" , cex = 1.2)
# Frame
box(which = "outer", lty = "solid")
return(compTab)
}
compTab <- AssROriginSellerCat()
compCap <- figureCaption(compCap, "Origin Prediction / Association Rules")
#----------------------------------------------------------------------
#                       Bayesian Network
#    with seller / origin / price / category / timestamp / sold_since / product_sold
#-----------------------------------------------------------------------
BayesNet <- function(){
#-----------------
#   New Data
#-----------------
# Select all "Drugs & Chemicals" ads
matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
bayesian.data <- data[matching_vector,]
# Select the column of the data that are interesting
# ie removing colunm like "id" or "url" that don't give any information
bayesian.data <- subset(bayesian.data, select=c(origin,category,seller,priceUnitDose, products_sold, sold_since, timestamp ))
# Subset : choose the colunm that you want
# Handling : column category
# Regular expression for spliting the categories
regex <- "/(.*)/(.*)/(.*)"
cat <- str_match(bayesian.data$category, regex)
bayesian.data$category <- cat[,3] # keep only the second part
#Get rid of lines with Null as products_sold value
bayesian.data <- bayesian.data[!is.element(bayesian.data$products_sold, "NULL"),]
#Convert products_sold to numeric and discretize it
bayesian.data$products_sold <- as.numeric(as.character(bayesian.data$products_sold))
#Given timestamp and sold_since calculate the lifetime of the ad
bayesian.data$sold_since <-  as.Date(bayesian.data$sold_since)
bayesian.data$timestamp <-  as.Date(bayesian.data$timestamp)
bayesian.data$timestamp <- bayesian.data$timestamp - bayesian.data$sold_since
bayesian.data$timestamp <- as.numeric(bayesian.data$timestamp)
# 1 day on the market at least
bayesian.data <- bayesian.data[which(bayesian.data$timestamp > 0),]
#Calculate profitability
bayesian.data$products_sold <- bayesian.data$products_sold / bayesian.data$timestamp * 30
names(bayesian.data)[match("products_sold",names(bayesian.data))] <- "profitability"
#Discretize profitability
nbCategory <- 5
bayesian.data$profitability <- arules::discretize(bayesian.data$profitability, method="frequency", categories = nbCategory)
bayesian.data <- subset(bayesian.data, select= -c(sold_since, timestamp))
#Convert variables to factor
bayesian.data$category <- as.factor(bayesian.data$category)
bayesian.data$seller <- as.factor(bayesian.data$seller)
bayesian.data$origin <- as.factor(bayesian.data$origin)
#Get rid of lines with NA as products_sold value
bayesian.data <- bayesian.data[!is.element(bayesian.data$profitability, NA),]
#---------------------
#   Bayesian Network
#---------------------
res <- hc(bayesian.data)
plot(res)
fittedbn <- bn.fit(res, data = bayesian.data)
prob.data <- data.frame(fittedbn$profitability$prob)
colnames(prob.data) <- c("Profitability", "Category", "Probability")
print(prob.data)
compTab <- TableCaption(compTab, "Categories Profitability")
#Handling interval
interv <- levels(bayesian.data$profitability)
interv <- unlist(strsplit(interv, ","))
interv <- gsub(pattern = "[^0-9.]*", replacement = "", interv)
interval <- data.frame(interv[seq(1, length(interv), 2)],interv[seq(2, length(interv), 2)])
colnames(interval) <- c("left", "right")
interval$left <- as.numeric(levels(interval$left))
interval$right <- as.numeric(levels(interval$right))
expectancy <- c()
#Calculate expectancy for each category
for(i in 0:(length(table(bayesian.data$category))-1)){
left <- 0
right <- 0
for(j in 1:nbCategory){
left<-left + interval$left[j] * fittedbn$profitability$prob[i*nbCategory + j]
right<-right + interval$right[j] * fittedbn$profitability$prob[i*nbCategory + j]
}
expectancy[i+1] <- paste("[", round(left,2) , "," , round(right,2) , "]")
}
affichage <-data.frame(names(table(bayesian.data$category)),expectancy)
colnames(affichage) <- c("Category", "Expectancy")
print(affichage)
compTab <- TableCaption(compTab, "Expectancies of category Profitability")
# Frame
box(which = "outer", lty = "solid")
mtext("Conditional dependency between variables" , cex = 1.2,side = 1)
return(compTab)
}
compTab <- BayesNet()
compCap <- figureCaption(compCap, "Variable Dependencies / Bayesian Neural Network")
source('C:/Internship/UEL-project/d3.js/World Map/createData.R', echo=TRUE)
setwd("C:/Internship/UEL-project")
source('C:/Internship/UEL-project/d3.js/World Map/createData.R', echo=TRUE)
max(perMonth)
source('C:/Internship/UEL-project/d3.js/World Map/createData.R', echo=TRUE)
source('C:/Internship/UEL-project/d3.js/World Map/createData.R', echo=TRUE)
install.packages("randomcoloR")
library(randomcoloR)
randomColor()
View(new.data)
View(new.data)
View(lat_long)
View(lat_long)
lat_long[ncol(lat_long)] <- rando;randomColor()
lat_long[ncol(lat_long)] <- randomColor()
View(lat_long)
View(lat_long)
for(i in 1:nrow(lat_long)){
lat_long[i,ncol(lat_long)] <- randomColor()
}
View(lat_long)
View(lat_long)
View(lat_long)
View(lat_long)
lat_long <- data.frame(Country = data_country$Country , long=  data_country$Longitude..average., lat=  data_country$Latitude..average.)
for(i in 1:nrow(lat_long)){
lat_long[i,ncol(lat_long)+1] <- randomColor()
}
lat_long <- data.frame(Country = data_country$Country , long=  data_country$Longitude..average., lat=  data_country$Latitude..average.)
for(i in 1:nrow(lat_long)){
lat_long[i,4] <- randomColor()
}
source('C:/Internship/UEL-project/d3.js/World Map/createData.R', echo=TRUE)
liste <- list()
for(i in 1: ncol(perMonth)){ 'ncol(perMonth)'
ligne <- list(date = "")
ligne["date"] <- colnames(perMonth)[i]
data.list <- list()
for(j in 1:nrow(perMonth)){  'nrow(perMonth)'
data.list<- append(data.list, list(list(name = rownames(perMonth)[j], radius= round(perMonth[j,i]/max(perMonth)*200,0), latitude = lat_long[lat_long==rownames(perMonth)[j],3 ] , longitude = lat_long[lat_long==rownames(perMonth)[j],2 ], color = lat_long[j,4])))
}
ligne <- append(ligne, list(data = data.list))
liste <- append(liste,list(ligne))
}
jsonOut<-toJSON(liste,pretty = TRUE,auto_unbox = TRUE)
#cat(jsonOut)
write(jsonOut, "dataWorldMapNew.json")
